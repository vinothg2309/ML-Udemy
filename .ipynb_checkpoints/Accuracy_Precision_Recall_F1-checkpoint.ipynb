{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age  EstimatedSalary  Purchased\n",
      "0   19            19000          0\n",
      "1   35            20000          0\n",
      "2   26            43000          0\n",
      "3   27            57000          0\n",
      "4   19            76000          0\n",
      "[[    19  19000]\n",
      " [    35  20000]\n",
      " [    26  43000]\n",
      " [    27  57000]\n",
      " [    19  76000]\n",
      " [    27  58000]\n",
      " [    27  84000]\n",
      " [    32 150000]\n",
      " [    25  33000]\n",
      " [    35  65000]\n",
      " [    26  80000]\n",
      " [    26  52000]\n",
      " [    20  86000]\n",
      " [    32  18000]\n",
      " [    18  82000]\n",
      " [    29  80000]\n",
      " [    47  25000]\n",
      " [    45  26000]\n",
      " [    46  28000]\n",
      " [    48  29000]\n",
      " [    45  22000]\n",
      " [    47  49000]\n",
      " [    48  41000]\n",
      " [    45  22000]\n",
      " [    46  23000]\n",
      " [    47  20000]\n",
      " [    49  28000]\n",
      " [    47  30000]\n",
      " [    29  43000]\n",
      " [    31  18000]\n",
      " [    31  74000]\n",
      " [    27 137000]\n",
      " [    21  16000]\n",
      " [    28  44000]\n",
      " [    27  90000]\n",
      " [    35  27000]\n",
      " [    33  28000]\n",
      " [    30  49000]\n",
      " [    26  72000]\n",
      " [    27  31000]\n",
      " [    27  17000]\n",
      " [    33  51000]\n",
      " [    35 108000]\n",
      " [    30  15000]\n",
      " [    28  84000]\n",
      " [    23  20000]\n",
      " [    25  79000]\n",
      " [    27  54000]\n",
      " [    30 135000]\n",
      " [    31  89000]\n",
      " [    24  32000]\n",
      " [    18  44000]\n",
      " [    29  83000]\n",
      " [    35  23000]\n",
      " [    27  58000]\n",
      " [    24  55000]\n",
      " [    23  48000]\n",
      " [    28  79000]\n",
      " [    22  18000]\n",
      " [    32 117000]\n",
      " [    27  20000]\n",
      " [    25  87000]\n",
      " [    23  66000]\n",
      " [    32 120000]\n",
      " [    59  83000]\n",
      " [    24  58000]\n",
      " [    24  19000]\n",
      " [    23  82000]\n",
      " [    22  63000]\n",
      " [    31  68000]\n",
      " [    25  80000]\n",
      " [    24  27000]\n",
      " [    20  23000]\n",
      " [    33 113000]\n",
      " [    32  18000]\n",
      " [    34 112000]\n",
      " [    18  52000]\n",
      " [    22  27000]\n",
      " [    28  87000]\n",
      " [    26  17000]\n",
      " [    30  80000]\n",
      " [    39  42000]\n",
      " [    20  49000]\n",
      " [    35  88000]\n",
      " [    30  62000]\n",
      " [    31 118000]\n",
      " [    24  55000]\n",
      " [    28  85000]\n",
      " [    26  81000]\n",
      " [    35  50000]\n",
      " [    22  81000]\n",
      " [    30 116000]\n",
      " [    26  15000]\n",
      " [    29  28000]\n",
      " [    29  83000]\n",
      " [    35  44000]\n",
      " [    35  25000]\n",
      " [    28 123000]\n",
      " [    35  73000]\n",
      " [    28  37000]\n",
      " [    27  88000]\n",
      " [    28  59000]\n",
      " [    32  86000]\n",
      " [    33 149000]\n",
      " [    19  21000]\n",
      " [    21  72000]\n",
      " [    26  35000]\n",
      " [    27  89000]\n",
      " [    26  86000]\n",
      " [    38  80000]\n",
      " [    39  71000]\n",
      " [    37  71000]\n",
      " [    38  61000]\n",
      " [    37  55000]\n",
      " [    42  80000]\n",
      " [    40  57000]\n",
      " [    35  75000]\n",
      " [    36  52000]\n",
      " [    40  59000]\n",
      " [    41  59000]\n",
      " [    36  75000]\n",
      " [    37  72000]\n",
      " [    40  75000]\n",
      " [    35  53000]\n",
      " [    41  51000]\n",
      " [    39  61000]\n",
      " [    42  65000]\n",
      " [    26  32000]\n",
      " [    30  17000]\n",
      " [    26  84000]\n",
      " [    31  58000]\n",
      " [    33  31000]\n",
      " [    30  87000]\n",
      " [    21  68000]\n",
      " [    28  55000]\n",
      " [    23  63000]\n",
      " [    20  82000]\n",
      " [    30 107000]\n",
      " [    28  59000]\n",
      " [    19  25000]\n",
      " [    19  85000]\n",
      " [    18  68000]\n",
      " [    35  59000]\n",
      " [    30  89000]\n",
      " [    34  25000]\n",
      " [    24  89000]\n",
      " [    27  96000]\n",
      " [    41  30000]\n",
      " [    29  61000]\n",
      " [    20  74000]\n",
      " [    26  15000]\n",
      " [    41  45000]\n",
      " [    31  76000]\n",
      " [    36  50000]\n",
      " [    40  47000]\n",
      " [    31  15000]\n",
      " [    46  59000]\n",
      " [    29  75000]\n",
      " [    26  30000]\n",
      " [    32 135000]\n",
      " [    32 100000]\n",
      " [    25  90000]\n",
      " [    37  33000]\n",
      " [    35  38000]\n",
      " [    33  69000]\n",
      " [    18  86000]\n",
      " [    22  55000]\n",
      " [    35  71000]\n",
      " [    29 148000]\n",
      " [    29  47000]\n",
      " [    21  88000]\n",
      " [    34 115000]\n",
      " [    26 118000]\n",
      " [    34  43000]\n",
      " [    34  72000]\n",
      " [    23  28000]\n",
      " [    35  47000]\n",
      " [    25  22000]\n",
      " [    24  23000]\n",
      " [    31  34000]\n",
      " [    26  16000]\n",
      " [    31  71000]\n",
      " [    32 117000]\n",
      " [    33  43000]\n",
      " [    33  60000]\n",
      " [    31  66000]\n",
      " [    20  82000]\n",
      " [    33  41000]\n",
      " [    35  72000]\n",
      " [    28  32000]\n",
      " [    24  84000]\n",
      " [    19  26000]\n",
      " [    29  43000]\n",
      " [    19  70000]\n",
      " [    28  89000]\n",
      " [    34  43000]\n",
      " [    30  79000]\n",
      " [    20  36000]\n",
      " [    26  80000]\n",
      " [    35  22000]\n",
      " [    35  39000]\n",
      " [    49  74000]\n",
      " [    39 134000]\n",
      " [    41  71000]\n",
      " [    58 101000]\n",
      " [    47  47000]\n",
      " [    55 130000]\n",
      " [    52 114000]\n",
      " [    40 142000]\n",
      " [    46  22000]\n",
      " [    48  96000]\n",
      " [    52 150000]\n",
      " [    59  42000]\n",
      " [    35  58000]\n",
      " [    47  43000]\n",
      " [    60 108000]\n",
      " [    49  65000]\n",
      " [    40  78000]\n",
      " [    46  96000]\n",
      " [    59 143000]\n",
      " [    41  80000]\n",
      " [    35  91000]\n",
      " [    37 144000]\n",
      " [    60 102000]\n",
      " [    35  60000]\n",
      " [    37  53000]\n",
      " [    36 126000]\n",
      " [    56 133000]\n",
      " [    40  72000]\n",
      " [    42  80000]\n",
      " [    35 147000]\n",
      " [    39  42000]\n",
      " [    40 107000]\n",
      " [    49  86000]\n",
      " [    38 112000]\n",
      " [    46  79000]\n",
      " [    40  57000]\n",
      " [    37  80000]\n",
      " [    46  82000]\n",
      " [    53 143000]\n",
      " [    42 149000]\n",
      " [    38  59000]\n",
      " [    50  88000]\n",
      " [    56 104000]\n",
      " [    41  72000]\n",
      " [    51 146000]\n",
      " [    35  50000]\n",
      " [    57 122000]\n",
      " [    41  52000]\n",
      " [    35  97000]\n",
      " [    44  39000]\n",
      " [    37  52000]\n",
      " [    48 134000]\n",
      " [    37 146000]\n",
      " [    50  44000]\n",
      " [    52  90000]\n",
      " [    41  72000]\n",
      " [    40  57000]\n",
      " [    58  95000]\n",
      " [    45 131000]\n",
      " [    35  77000]\n",
      " [    36 144000]\n",
      " [    55 125000]\n",
      " [    35  72000]\n",
      " [    48  90000]\n",
      " [    42 108000]\n",
      " [    40  75000]\n",
      " [    37  74000]\n",
      " [    47 144000]\n",
      " [    40  61000]\n",
      " [    43 133000]\n",
      " [    59  76000]\n",
      " [    60  42000]\n",
      " [    39 106000]\n",
      " [    57  26000]\n",
      " [    57  74000]\n",
      " [    38  71000]\n",
      " [    49  88000]\n",
      " [    52  38000]\n",
      " [    50  36000]\n",
      " [    59  88000]\n",
      " [    35  61000]\n",
      " [    37  70000]\n",
      " [    52  21000]\n",
      " [    48 141000]\n",
      " [    37  93000]\n",
      " [    37  62000]\n",
      " [    48 138000]\n",
      " [    41  79000]\n",
      " [    37  78000]\n",
      " [    39 134000]\n",
      " [    49  89000]\n",
      " [    55  39000]\n",
      " [    37  77000]\n",
      " [    35  57000]\n",
      " [    36  63000]\n",
      " [    42  73000]\n",
      " [    43 112000]\n",
      " [    45  79000]\n",
      " [    46 117000]\n",
      " [    58  38000]\n",
      " [    48  74000]\n",
      " [    37 137000]\n",
      " [    37  79000]\n",
      " [    40  60000]\n",
      " [    42  54000]\n",
      " [    51 134000]\n",
      " [    47 113000]\n",
      " [    36 125000]\n",
      " [    38  50000]\n",
      " [    42  70000]\n",
      " [    39  96000]\n",
      " [    38  50000]\n",
      " [    49 141000]\n",
      " [    39  79000]\n",
      " [    39  75000]\n",
      " [    54 104000]\n",
      " [    35  55000]\n",
      " [    45  32000]\n",
      " [    36  60000]\n",
      " [    52 138000]\n",
      " [    53  82000]\n",
      " [    41  52000]\n",
      " [    48  30000]\n",
      " [    48 131000]\n",
      " [    41  60000]\n",
      " [    41  72000]\n",
      " [    42  75000]\n",
      " [    36 118000]\n",
      " [    47 107000]\n",
      " [    38  51000]\n",
      " [    48 119000]\n",
      " [    42  65000]\n",
      " [    40  65000]\n",
      " [    57  60000]\n",
      " [    36  54000]\n",
      " [    58 144000]\n",
      " [    35  79000]\n",
      " [    38  55000]\n",
      " [    39 122000]\n",
      " [    53 104000]\n",
      " [    35  75000]\n",
      " [    38  65000]\n",
      " [    47  51000]\n",
      " [    47 105000]\n",
      " [    41  63000]\n",
      " [    53  72000]\n",
      " [    54 108000]\n",
      " [    39  77000]\n",
      " [    38  61000]\n",
      " [    38 113000]\n",
      " [    37  75000]\n",
      " [    42  90000]\n",
      " [    37  57000]\n",
      " [    36  99000]\n",
      " [    60  34000]\n",
      " [    54  70000]\n",
      " [    41  72000]\n",
      " [    40  71000]\n",
      " [    42  54000]\n",
      " [    43 129000]\n",
      " [    53  34000]\n",
      " [    47  50000]\n",
      " [    42  79000]\n",
      " [    42 104000]\n",
      " [    59  29000]\n",
      " [    58  47000]\n",
      " [    46  88000]\n",
      " [    38  71000]\n",
      " [    54  26000]\n",
      " [    60  46000]\n",
      " [    60  83000]\n",
      " [    39  73000]\n",
      " [    59 130000]\n",
      " [    37  80000]\n",
      " [    46  32000]\n",
      " [    46  74000]\n",
      " [    42  53000]\n",
      " [    41  87000]\n",
      " [    58  23000]\n",
      " [    42  64000]\n",
      " [    48  33000]\n",
      " [    44 139000]\n",
      " [    49  28000]\n",
      " [    57  33000]\n",
      " [    56  60000]\n",
      " [    49  39000]\n",
      " [    39  71000]\n",
      " [    47  34000]\n",
      " [    48  35000]\n",
      " [    48  33000]\n",
      " [    47  23000]\n",
      " [    45  45000]\n",
      " [    60  42000]\n",
      " [    39  59000]\n",
      " [    46  41000]\n",
      " [    51  23000]\n",
      " [    50  20000]\n",
      " [    36  33000]\n",
      " [    49  36000]]\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "dataset=pd.read_csv(\"Section 3:Classification/K Nearest Neighbor(KNN)/Social_Network_Ads.csv\")\n",
    "print(dataset.head())\n",
    "X=dataset.iloc[:,:-1].values\n",
    "y=dataset.iloc[:,-1:].values\n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting dataset to Training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.25,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featuring scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training K-NN model on training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN calculates euclidean distance between new data with trained data to classify new incoming data\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# n_neighbors-No of neighbors to consider(default:5),weights \n",
    "classifier=KNeighborsClassifier(n_neighbors=5, metric='minkowski',p=2)\n",
    "# ravel - returns array with same memory reference as original array shape (n_samples,). Changing value with refect changes in original array\n",
    "# flatten - returns copy of original array(shape (n_samples,1)). Changing value won't affect original array\n",
    "classifier.fit(X_train,np.ravel(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting new result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1]\n"
     ]
    }
   ],
   "source": [
    "print(classifier.predict(sc.transform([[30,87000]])))\n",
    "print(classifier.predict(sc.transform([[36,144000]])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row is 1(Positive) & second row is 0(Negative) in this case :\n",
      " [[29  3]\n",
      " [ 4 64]]\n",
      "First row is 0(Positive) & second row is 1(Negative) in this case :\n",
      " [[29  3]\n",
      " [ 4 64]]\n",
      "[[29  3]\n",
      " [ 4 64]]\n",
      "tp :  29  fn :  3  fp :  4  fn :  3\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print('First row is 1(Positive) & second row is 0(Negative) in this case :\\n',confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "print('First row is 0(Positive) & second row is 1(Negative) in this case :\\n',confusion_matrix(y_test, y_pred, labels=[1,0]))\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "print(cm)\n",
    "\n",
    "cm1 = confusion_matrix(y_test, y_pred, labels=[1,0])\n",
    "print('cm1 : ', cm1)\n",
    "\n",
    "tp, fn, fp, tn = cm.reshape(-1);\n",
    "print('tp : ', tp, ' fn : ', fn, \" fp : \", fp, \" fn : \", fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy is the most intuitive performance measure and it is simply a ratio of correctly predicted observation to the total observations. One may think that, if we have high accuracy then our model is best. Yes, accuracy is a great measure but only when you have symmetric datasets where values of false positive and false negatives are almost same. Therefore, you have to look at other parameters to evaluate the performance of your model.\n",
    "\n",
    "Accuracy = TP+TN/TP+FP+FN+TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score :  0.93\n",
      "cal_acc_score :  0.93\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print('accuracy_score : ',acc)\n",
    "\n",
    "cal_acc_score = (tp+tn)/(tp+fn+fp+tn)\n",
    "print('cal_acc_score : ', cal_acc_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is the ratio of correctly predicted positive observations to the total predicted positive observations. The question that this metric answer is of all passengers that labeled as survived, how many actually survived? High precision relates to the low false positive rate. We have got 0.788 precision which is pretty good.\n",
    "\n",
    "Precision = TP/TP+FP\n",
    "\n",
    "Precision is a useful metric in cases where False Positive is a higher concern than False Negatives.\n",
    "For instance, email spam detection. In email spam detection, a false positive means that an email that is non-spam (actual negative) has been identified as spam (predicted spam). The email user might lose important emails if the precision is not high for the spam detection model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision 0 :  0.9552238805970149\n",
      "Precision 1 :  0.8787878787878788\n"
     ]
    }
   ],
   "source": [
    "precision_0 = tp/(tp+fp)\n",
    "precision_1 = tn/(tn+fn)\n",
    "print('Precision 0 : ', precision_0 )\n",
    "print('Precision 1 : ', precision_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recall Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall (Sensitivity) - Recall is the ratio of correctly predicted positive observations to the all observations in actual class - yes. The question recall answers is: Of all the passengers that truly survived, how many did we label? We have got recall of 0.631 which is good for this model as it’s above 0.5.\n",
    "\n",
    "Recall = TP/TP+FN\n",
    "\n",
    "Applying the same understanding, we know that Recall shall be the model metric we use to select our best model when there is a high cost associated with False Negative. For instance, in fraud detection or sick patient detection. If a fraudulent transaction (Actual Positive) is predicted as non-fraudulent (Predicted Negative), the consequence can be very bad for the bank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall 0 :  0.9411764705882353\n",
      "Recall 1 :  0.90625\n"
     ]
    }
   ],
   "source": [
    "recall_0 = tp/(tp+fn)\n",
    "recall_1 = tn/(fp+tn)\n",
    "print('Recall 0 : ', tp/(tp+fn))\n",
    "print('Recall 1 : ', tn/(fp+tn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F-1 Score Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In practice, when we try to increase the precision of our model, the recall goes down, and vice-versa. The F1-score captures both the trends in a single value. F1 Score is needed when you want to seek a balance between Precision and Recall. Right…so what is the difference between F1 Score and Accuracy then? We have previously seen that accuracy can be largely contributed by a large number of True Negatives which in most business circumstances, we do not focus on much whereas False Negative and False Positive usually has business costs (tangible & intangible) thus F1 Score might be a better measure to use if we need to seek a balance between Precision and Recall AND there is an uneven class distribution (large number of Actual Negatives).\n",
    "\n",
    "Takes into account how the data is distributed. Useful when you have data with imbalance classes.\n",
    "\n",
    "F1 Score = 2*(Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1_score_0 :  0.9481481481481482\n",
      "f1_score_1 :  0.8923076923076922\n"
     ]
    }
   ],
   "source": [
    "f1_score_0 = 2*((precision_0*recall_0)/(precision_0+recall_0))\n",
    "f1_score_1 = 2*((precision_1*recall_1)/(precision_1+recall_1))\n",
    "print(\"f1_score_0 : \", f1_score_0)\n",
    "print(\"f1_score_1 : \", f1_score_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using classification_report to calculate everthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.94      0.95        68\n",
      "           1       0.88      0.91      0.89        32\n",
      "\n",
      "    accuracy                           0.93       100\n",
      "   macro avg       0.92      0.92      0.92       100\n",
      "weighted avg       0.93      0.93      0.93       100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "cp = classification_report(y_test, y_pred)\n",
    "print(cp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
